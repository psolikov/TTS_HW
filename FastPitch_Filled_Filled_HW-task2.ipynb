{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O63jbuhHNNQ"
      },
      "source": [
        "# Задание 1\n",
        "\n",
        "В этом задании вам предстоит сделать так, чтобы TTS начал говорить другим голосом так, чтобы можно было контролировать интонации путем присвоения токена каждому слову.\n",
        "\n",
        "**Важно!** Добавьте ссылку на свой форк с гитхаба в команду git clone"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch==1.10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYapv4IVhorr",
        "outputId": "009e9b60-86e0-4704-a028-3360d385fa7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.10 in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4klUk-k1t71j",
        "outputId": "86b31704-6e08-45be-ee72-756505d5149e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDHLj20YgAvM"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/psolikov/TTS_HW\n",
        "!cd TTS_HW && curl gdrive.sh | bash -s https://drive.google.com/file/d/1ubAsUdWqHFY3MZJZVLqzxjH6lR_hKRyz/view?usp=sharing \n",
        "!cd TTS_HW && tar -xf libri_training_data.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boJ5yB0Qbt0f"
      },
      "outputs": [],
      "source": [
        "# ! curl gdrive.sh | bash -s https://drive.google.com/file/d/1XIUvH0QXcZ6Ev0DbNSPGJIdC3-h03Sx9/view?usp=sharing\n",
        "!!gdown --id 1XIUvH0QXcZ6Ev0DbNSPGJIdC3-h03Sx9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip file.zip -d down_file/\n"
      ],
      "metadata": {
        "id": "omul1ou_3bcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r down_file/content/TTS_HW/libri_training_data/ /content/TTS_HW/libri_training_data/"
      ],
      "metadata": {
        "id": "SIfHKUQP3dnh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC7vwtutHNNQ"
      },
      "source": [
        "## Важно!\n",
        "\n",
        "Следующая ячейка будет устанавливать библиотеку Apex, на колабе это может занять **12-20** минут! К сожалению, без этой библиотеки обучение данной реализации сети будет длиться слишком медленно, также из этой библиотеки используется оптимайзер FusedLamb, если же использовать стандартный Adam, обучение может стать нестабильным.\n",
        "\n",
        "Если у вас есть своя локальная GPU, рекомендую использовать docker контейнер с Nvidia GPU Cloud - `nvcr.io/nvidia/pytorch:21.06-py3`, там эта библиотека уже предустановлена."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jis6m-nGh6md"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import apex\n",
        "except Exception:\n",
        "  ! git clone https://github.com/NVIDIA/apex.git\n",
        "  % cd apex\n",
        "  !pip install --target=$nb_path --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" .\n",
        "  %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aftI_sKBbyFF",
        "outputId": "047c48a7-2779-43e4-af0d-eef4af1da75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/apex\n",
            "HEAD is now at a651e2c sync-free Distributed LAMB + parameter reordering (#1055)\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "% cd apex\n",
        "! git reset --hard a651e2c\n",
        "% cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bPXURAgqcph"
      },
      "outputs": [],
      "source": [
        "!pip install -r TTS_HW/requirements.txt\n",
        "!pip install transformers\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ffhu23FHNNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f46628-031b-43cd-8645-343ab17a0e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cmudict-0.7b ...\n",
            "nvidia_fastpitch_210824.pt already downloaded.\n",
            "nvidia_waveglow256pyt_fp16.pt already downloaded.\n"
          ]
        }
      ],
      "source": [
        "!cd TTS_HW && bash scripts/download_cmudict.sh\n",
        "!cd TTS_HW && bash scripts/download_fastpitch.sh\n",
        "!cd TTS_HW && bash scripts/download_waveglow.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSgZ01YQHNNQ"
      },
      "source": [
        "### Описание задачи\n",
        "Выше была склонирована оригинальная имплементация FastPitch [отсюда](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/FastPitch). В ней изменен лишь даталоадер - в батче помимо текста и целевой мелспектрограммы, также возвращаются токены `Prominencе`. Необходимо понять, как можно использовать эти токены и в какое место сети необходимо их добавить, чтобы затем, на инференсе, можно было контролировать интонации.\n",
        "\n",
        "Так как мы сильно ограничены в ресурсах - обучать сеть с нуля не получится, необходимо лишь провести finetuning с оригинального чекпоинта от Nvidia, обученного на датасете LJSpeech. От вас требуется дообучить сеть на одном из голосов из датасета LibriTTS.\n",
        "\n",
        "Все данные уже предобработаны и загружены, токены `Prominence` были извлечены с помощью [Wavelet Prosody Toolkit](https://github.com/asuni/wavelet_prosody_toolkit). Эти значения были квантизированы, в данных могут встречаться лишь значения 1, 2, 3. Эти значения извлечены для каждого слова и продублированы для каждой фонемы.\n",
        "\n",
        "Из-за особенностей имплементации засовывать обучение в ноутбук крайне неудобно, поэтому предлагается изменить файлы исходного кода прямо открывая их в колабе (они видны в файл менеджере слева), а затем запустить обучение, выполнив ячейку ниже. Чтобы не потерять свои изменения, рекомендую, изменив файлы, просто коммитить их к себе в репозиторий прямо из колаба. Не забывайте это делать часто, так как колаб любит уничтожать вашу среду, даже если вы просто отошли попить кофе.\n",
        "\n",
        "Уже 10 эпох обучения достаточно (около 15 минут обучения), чтобы была слышна разница. Mel loss должен опуститься где-то до значений 0.2-0.3, чтобы TTS звучал нормально. Так как данных очень мало, то если вы оставите сеть учиться надолго, скорее всего она переобучится, поэтому учить сильно дольше 20 эпох нет смысла."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqqRo_Qk9dLg",
        "outputId": "da4a9c1d-3852-445e-bfce-a44123375152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/output': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir /content/output/modules_inputs/"
      ],
      "metadata": {
        "id": "EPlkB8mC99ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJAVBCMv_Y81",
        "outputId": "fcf9c7b5-a76f-4c5c-a888-042468d33053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apex\t   file.zip\t\t      input-from-train.pt  sample_data\n",
            "down_file  input-from-train-batch.pt  output\t\t   TTS_HW\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/output/modules_inputs"
      ],
      "metadata": {
        "id": "NXGlCbaRF4KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/output/modules_inputs"
      ],
      "metadata": {
        "id": "VpQfH6CeGysO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dcsDcZ7HyEP"
      },
      "outputs": [],
      "source": [
        "!cd TTS_HW && bash scripts/train.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aQOP-BQHNNQ"
      },
      "source": [
        "После того как обучили сеть, прогоните ее на одной заданной фразе с разными значениями `Prominence`. Для этого в файле `inference.py` измените 384 строчку и запустите ячейку ниже. С разными значениями prominence фраза \"What a day\" должна произноситься с разной интонацией. Если вы этого добились, значит задание выполнено."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5CjgMCodcVb"
      },
      "outputs": [],
      "source": [
        "# !cd TTS_HW && bash scripts/inference_example.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "f4buJVBaFP9k",
        "outputId": "32436116-af8b-4de9-acf2-8e8ba69d1a7a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-346ed0121b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/output/audio_phrase_1_64.txt/audio_0.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m_make_wav\u001b[0;34m(self, data, rate)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mnchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/content/output/audio_phrase_1_64.txt/audio_0.wav'"
          ]
        }
      ],
      "source": [
        "import IPython\n",
        "IPython.display.Audio('/content/output/audio_phrase_1_64.txt/audio_0.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "dDx0sQ3UKKBa",
        "outputId": "e73fbd6f-ced7-409b-a7f0-f2e81414315e"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-346ed0121b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/output/audio_phrase_1_64.txt/audio_0.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m_make_wav\u001b[0;34m(self, data, rate)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mnchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/content/output/audio_phrase_1_64.txt/audio_0.wav'"
          ]
        }
      ],
      "source": [
        "import IPython\n",
        "IPython.display.Audio('/content/output/audio_phrase_1_64.txt/audio_0.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY3Ddfhw151O",
        "outputId": "f5b89909-17a4-4f54-f8bf-b48655ccf382"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1+3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjMmmSyXHNNQ"
      },
      "source": [
        "# Задание 2 (5 баллов)\n",
        "\n",
        "Это хорошо, что мы научились контролировать интонацию в произносимых фразах, но что делать на инференсе, ведь у нас нет этих значений `Prominence`? Можно попробовать научиться предсказывать их из текста. Для этого можно обучить какую-нибудь LM, при этом учить с нуля также не имеет смысла.\n",
        "\n",
        "В задании предлагается заполнить отсутствующие ячейки ниже. Необходимый для зачета F1 score на тестовой выборке должен быть около `0.75`. Не забудьте про маски!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torchmetrics"
      ],
      "metadata": {
        "id": "hkpOdv7pGx0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nBYaR3JEkvTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "330421d1-1b70-454d-dfe2-e6b037fdd3b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dllogger\n",
            "  Using cached DLLogger-0.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r TTS_HW/requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r TTS_HW/requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from -r TTS_HW/requirements.txt (line 3)) (2.1.0)\n",
            "Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.7/dist-packages (from -r TTS_HW/requirements.txt (line 4)) (0.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r TTS_HW/requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: tensorboardX==2.0 in /usr/local/lib/python3.7/dist-packages (from -r TTS_HW/requirements.txt (line 6)) (2.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (0.10.3.post1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (0.51.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.0->-r TTS_HW/requirements.txt (line 6)) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.0->-r TTS_HW/requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (0.34.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->pooch>=1.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0->-r TTS_HW/requirements.txt (line 4)) (2.21)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r TTS_HW/requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r TTS_HW/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r TTS_HW/requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (0.3.2)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.7)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r TTS_HW/requirements.txt\n",
        "!pip install transformers\n",
        "!pip install torchmetrics\n",
        "!pip install seqeval\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForTokenClassification, BertTokenizer, BertConfig, BertModel\n",
        "from tqdm import tqdm\n",
        "import torchmetrics\n",
        "\n",
        "device='cuda:0'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls TTS_HW/libri_training_data"
      ],
      "metadata": {
        "id": "UyPj704LSnHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 50 \"TTS_HW/libri_training_data/40_121026_000178_000000.TextGrid\"\n"
      ],
      "metadata": {
        "id": "iYhD6nXqVI9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tail \"TTS_HW/libri_training_data/40_121026_000178_000000.prom\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0CPIedWDYua",
        "outputId": "e95af029-85fa-40f5-ae59-48978a3eac69"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40_121026_000178_000000\t7.250\t7.700\tgaze\t0.611\t0.769\n",
            "40_121026_000178_000000\t7.700\t7.820\tand\t0.347\t0.000\n",
            "40_121026_000178_000000\t7.820\t8.380\tcontracted\t0.882\t0.360\n",
            "40_121026_000178_000000\t8.380\t9.020\tfeatures\t0.732\t1.842\n",
            "40_121026_000178_000000\t9.340\t9.760\tdumb\t1.672\t0.135\n",
            "40_121026_000178_000000\t9.760\t9.990\tand\t0.775\t0.000\n",
            "40_121026_000178_000000\t9.990\t10.620\tmotionless\t0.237\t1.103\n",
            "40_121026_000178_000000\t10.620\t10.760\tas\t0.205\t0.000\n",
            "40_121026_000178_000000\t10.760\t10.830\ta\t0.094\t0.006\n",
            "40_121026_000178_000000\t10.830\t11.330\tstatue\t1.124\t1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\" \".join([\"a\", \"b\", \"c\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "8y7vLRn9ceUb",
        "outputId": "6b7b2dec-c766-49f3-932f-1699a65806c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a b c'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "label_proms = []\n",
        "label_boundaries = []\n",
        "for filename in tqdm(Path('TTS_HW/libri_training_data').glob('*.prom')):\n",
        "    #####################\n",
        "    ##### YOUR CODE #####\n",
        "    #####################\n",
        "    # pass\n",
        "    with open(filename, \"r\") as f:\n",
        "      sentence = []\n",
        "      label_prom_s = []\n",
        "      for line in f.readlines():\n",
        "        x = float(line.split()[-2])\n",
        "        y = float(line.split()[-1])\n",
        "        sentence.append(line.split()[3])\n",
        "        label_prom_s.append(y)\n",
        "      label_proms.append(label_prom_s)\n",
        "      sentences.append(\" \".join(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_crtreuBDFhH",
        "outputId": "e83b33c1-72b2-49ea-d30e-a565efeff94f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "341it [00:00, 10481.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RAOU2bk4w_Wg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    flat_preds = np.argmax(preds, axis=2).flatten()\n",
        "    flat_labels = labels.flatten()\n",
        "    return np.sum(flat_preds == flat_labels)/len(flat_labels)"
      ],
      "metadata": {
        "id": "je8mUhbm4MZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wj9MZoyLHNNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67fa38f-117b-4772-e467-47545706d7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "341it [00:00, 11121.06it/s]\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/67 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "loss; 0.5625361204147339: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.8153408765792847\n",
            "EPOCH:1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.387619286775589: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.8130435347557068\n",
            "EPOCH:2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.2783969044685364: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.8250445127487183\n",
            "EPOCH:3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.1823897361755371: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.8148521184921265\n",
            "EPOCH:4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.1686333417892456: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.811302661895752\n",
            "EPOCH:5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.14488650858402252: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7991758584976196\n",
            "EPOCH:6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.07261921465396881: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7645329236984253\n",
            "EPOCH:7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.030442317947745323: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7843306660652161\n",
            "EPOCH:8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.004809824749827385: 100%|██████████| 67/67 [00:27<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7631248235702515\n",
            "EPOCH:9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss; 0.0017264668131247163: 100%|██████████| 67/67 [00:27<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7843306660652161\n"
          ]
        }
      ],
      "source": [
        "def val_to_class(val):\n",
        "    if val < 1:\n",
        "        return 0\n",
        "    if 1 < val < 2:\n",
        "        return 1\n",
        "    return 2\n",
        "\n",
        "f1_criterion = torchmetrics.F1(num_classes=3)\n",
        "acc_criterion = torchmetrics.Accuracy(num_classes=3)\n",
        "\n",
        "class PromDataset(Dataset):\n",
        "    def __init__(self, tokenizer, sentences, labels, max_len):\n",
        "        self.len = len(sentences)\n",
        "        self.sentences = sentences\n",
        "        self.labels = [[val_to_class(label) for label in label_s] for label_s in labels]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        # self.texts = [tokenizer(text, \n",
        "        #                        padding='max_length', max_length = 512, truncation=True,\n",
        "        #                         return_tensors=\"pt\") for text in self.sentences]\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        #####################\n",
        "        ##### YOUR CODE #####\n",
        "        #####################\n",
        "        # input_token = self.texts[index]\n",
        "        sentence = str(self.sentences[index])\n",
        "        input_token = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = input_token[\"input_ids\"]\n",
        "        mask = input_token[\"attention_mask\"]\n",
        "        label = self.labels[index]\n",
        "        label.extend([0]*200)\n",
        "        label=label[:200]\n",
        "        # print(f\"mask len: {len(mask[0])}, label len: {len(label)}\")\n",
        "        # label += [-1] * (len(mask[0]) - len(label))\n",
        "        # print((mask.shape[0] - len(label)))\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'tags': torch.tensor(label, dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "sentences = []\n",
        "label_proms = []\n",
        "label_boundaries = []\n",
        "for filename in tqdm(Path('TTS_HW/libri_training_data').glob('*.prom')):\n",
        "    #####################\n",
        "    ##### YOUR CODE #####\n",
        "    #####################\n",
        "    # pass\n",
        "    with open(filename, \"r\") as f:\n",
        "      sentence = []\n",
        "      label_prom_s = []\n",
        "      for line in f.readlines():\n",
        "        x = float(line.split()[-2])\n",
        "        y = float(line.split()[-1])\n",
        "        sentence.append(line.split()[3])\n",
        "        label_prom_s.append(y)\n",
        "      label_proms.append(label_prom_s)\n",
        "      sentences.append(\" \".join(sentence))\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "train_dataset = PromDataset(tokenizer, sentences[:-10], label_proms[:-10], 200)\n",
        "test_dataset = PromDataset(tokenizer, sentences[-10:], label_proms[-10:], 200)\n",
        "\n",
        "# training_loader = DataLoader(train_dataset, batch_size=24, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
        "training_loader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "\n",
        "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=3)##### YOUR CODE #####\n",
        "model.to(device)\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=2e-05)\n",
        "for epoch in range(10):\n",
        "    print(f\"EPOCH:{epoch}\")\n",
        "    t_bar = tqdm(training_loader)\n",
        "    model.train()\n",
        "    accs = []\n",
        "    f1_scores = []\n",
        "    for batch in t_bar:\n",
        "        optimizer.zero_grad()\n",
        "        # print(batch)\n",
        "        in_ids, mask, tags = batch[\"ids\"].to(device, dtype = torch.long),\\\n",
        "         batch[\"mask\"].to(device, dtype = torch.long), batch[\"tags\"].to(device, dtype = torch.long)\n",
        "        # tags += 1\n",
        "        # print(batch)\n",
        "        # labels = torch.tensor([1] * in_ids.size(1)).unsqueeze(0)\n",
        "        # out = model(**in_ids, labels=mask)\n",
        "        loss = model(in_ids, mask, labels = tags)[0]\n",
        "        loss.backward()\n",
        "\n",
        "        # loss = f1_criterion(out, tags)\n",
        "\n",
        "        # acc = acc_criterion(out, tags)\n",
        "        # accs.append(acc)\n",
        "        # f1_scores.append(acc)\n",
        "        #####################\n",
        "        ##### YOUR CODE #####\n",
        "        #####################\n",
        "        t_bar.set_description(desc=f'loss; {loss.item()}')\n",
        "        optimizer.step()\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        accs = []\n",
        "        f1_scores = []\n",
        "\n",
        "        # predictions , true_labels = [], []\n",
        "\n",
        "        for batch in test_loader:\n",
        "            #####################\n",
        "            ##### YOUR CODE #####\n",
        "            #####################\n",
        "            predictions , true_labels = [], []\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['tags'].to(device, dtype = torch.long)\n",
        "\n",
        "            output = model(ids, mask, labels=targets)\n",
        "            logits = output[1]\n",
        "            out = torch.softmax(logits, dim=2)\n",
        "            _, out = torch.max(out, dim=2)\n",
        "            out_t = out[mask.type(torch.bool)].reshape(torch.sum(mask))\n",
        "            targets_t = targets[mask.type(torch.bool)].reshape(torch.sum(mask))\n",
        "            f1 = f1_criterion(out_t.to(\"cpu\"), targets_t.to(\"cpu\"))\n",
        "            f1_scores.append(f1)\n",
        "            # accs.append(torch.tensor(0.1))\n",
        "            # print(out_t.shape, targets_t.shape)\n",
        "            # loss, logits = output[:2]\n",
        "            # logits_cpu = logits.detach().cpu().numpy()\n",
        "            # label_ids = targets.to('cpu').numpy()\n",
        "            # predictions.extend([list(p) for p in np.argmax(logits_cpu, axis=2)])\n",
        "            # true_labels.append(label_ids)\n",
        "            # # acc = acc_criterion(logits, targets)\n",
        "            # # print(predictions, true_labels)\n",
        "            # acc=0\n",
        "            # # acc = acc_criterion(torch.tensor(predictions, dtype=torch.long), torch.tensor(true_labels, dtype=torch.long))\n",
        "            # # eval_loss += loss.mean().item()\n",
        "            # f1 = f1_criterion(torch.tensor(predictions[0], dtype=torch.long), torch.tensor(true_labels, dtype=torch.long))\n",
        "            # f1_scores.append(f1)\n",
        "            # accs.append(acc)\n",
        "\n",
        "\n",
        "            # pass\n",
        "\n",
        "    # print(f\"Accuracy: {torch.mean(torch.stack(accs)).item()}\")\n",
        "    print(f\"F1 score: {torch.mean(torch.stack(f1_scores)).item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in test_dataset:\n",
        "  print(x)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FRMMMY-6YLe",
        "outputId": "b972dde0-52b7-4041-d5ab-d76f16c85e74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': tensor([  101, 18257,  4208,  1163,  1677,  1465,  1103,  8228,  1377, 23373,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0]), 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'tags': tensor([0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1eGCwb8HNNQ"
      },
      "source": [
        "Стоит отметить, что мы обучаем сеть на очень небольшом наборе данных - если же файнтюнить на полном ТТС датасете, то точность предсказаний меток может достичь 0.95, поэтому такую сеть можно использовать при реальном инференсе для более точного предсказания интонаций."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_dataset:\n",
        "  print(x)\n",
        "  breaK"
      ],
      "metadata": {
        "id": "Grxyyz8CmHNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkaUoWIjHNNQ"
      },
      "source": [
        "# Задание 3 (5 баллов) (опционально)\n",
        "Если по какой-то причине что-то не получилось в предыдущих заданиях, то можно попробовать подготовить модель к инференсу. Задача - заэкспортировать код модели в ONNX, и проверить, что он работает.\n",
        "Подсказка - вся модель скорее всего не заэкспортится сразу, стоит пробовать делать это по модулям, а если какая-то функция не поддерживается ONNX, то ее можно выделить отдельно и заэкспортировать, например, в TorchScript. На выходе ожидается, что есть набор onnx или torchscript модулей, выполнив последовательно которые можно получить тот же выход, что и при запуске модели на PyTorch.\n",
        "\n",
        "Задание - по желанию, если не хочется делать что-то из того, что выше!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/output/models/"
      ],
      "metadata": {
        "id": "NaeLgoFKNRdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiZjqXr9baZ9",
        "outputId": "5f342753-fccf-4ae2-92c0-ac71ee551e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: Global batch size changed from 256 to 10.\n",
            "\n",
            "AMP=true, 1x5x2 (global batch size 10)\n",
            "\n",
            "train.py:46: UserWarning: PyProf is unavailable\n",
            "  warnings.warn('PyProf is unavailable')\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 52, in <module>\n",
            "    import amp_C\n",
            "ImportError: /usr/local/lib/python3.7/dist-packages/amp_C.cpython-37m-x86_64-linux-gnu.so: undefined symbol: _ZN3c106detail23torchInternalAssertFailEPKcS2_jS2_S2_\n",
            "Killing subprocess 3257\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 340, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 326, in main\n",
            "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 301, in sigkill_handler\n",
            "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'train.py', '--local_rank=0', '--cuda', '-o', './output', '--log-file', './output/nvlog.json', '--dataset-path', 'libri_training_data', '--training-files', 'libri_transcripts.txt', '--validation-files', 'libri_transcripts_val.txt', '-bs', '5', '--grad-accumulation', '2', '--optimizer', 'lamb', '--epochs', '10', '--epochs-per-checkpoint', '10', '--warmup-steps', '1000', '-lr', '0.1', '--weight-decay', '1e-6', '--grad-clip-thresh', '1000.0', '--dur-predictor-loss-scale', '0.1', '--pitch-predictor-loss-scale', '0.1', '--checkpoint-path', 'pretrained_models/fastpitch/nvidia_fastpitch_210824.pt', '--kl-loss-start-epoch', '0', '--kl-loss-warmup-epochs', '100', '--text-cleaners', 'english_cleaners_v2', '--n-speakers', '1', '--amp', '--p-arpabet', '1.0', '--energy-conditioning', '--load-mel-from-disk', '--load-pitch-from-disk']' returned non-zero exit status 1.\n"
          ]
        }
      ],
      "source": [
        "!cd TTS_HW && bash scripts/train.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-pYLJILSalR",
        "outputId": "74c6508f-53a7-4bd7-f18b-22238d2f148f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'TTS_HW/output/FastPitch_checkpoint_[1].pt'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "! ls TTS_HW/output/FastPitch_checkpoint_[1].pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBb1lcIOOZor"
      },
      "outputs": [],
      "source": [
        "!python TTS_HW/export_torchscript.py --generator-name FastPitch --generator-checkpoint TTS_HW/output/FastPitch_checkpoint_[1].pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBI8ffr9OdOC",
        "outputId": "088438c4-ffb9-45d3-d31f-8965ff526404"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1+2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8SL8-17aMg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c49ce49-2481-4887-825c-b3f716081947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastPitch_trchscript_FastPitch.onnx\n"
          ]
        }
      ],
      "source": [
        "ls /content/output/models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRLKHQ7Qbe4i",
        "outputId": "dd6ce61f-9373-46ce-cd18-c9b4608e135f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.8\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat /usr/local/lib/python3.7/dist-packages/torch/_sources.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOjl81D-KpCy",
        "outputId": "49ab9d1d-d50e-4f2b-dcbb-5f3210120c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import ast\n",
            "import functools\n",
            "import inspect\n",
            "from textwrap import dedent\n",
            "from typing import Any, Optional, Tuple, List, NamedTuple\n",
            "from torch._C import ErrorReport\n",
            "from torch._C._jit_tree_views import SourceRangeFactory\n",
            "\n",
            "def get_source_lines_and_file(\n",
            "    obj: Any,\n",
            "    error_msg: Optional[str] = None,\n",
            ") -> Tuple[List[str], int, Optional[str]]:\n",
            "    \"\"\"\n",
            "    Wrapper around inspect.getsourcelines and inspect.getsourcefile.\n",
            "\n",
            "    Returns: (sourcelines, file_lino, filename)\n",
            "    \"\"\"\n",
            "    filename = None  # in case getsourcefile throws\n",
            "    try:\n",
            "        filename = inspect.getsourcefile(obj)\n",
            "        sourcelines, file_lineno = inspect.getsourcelines(obj)\n",
            "    except OSError as e:\n",
            "        msg = (f\"Can't get source for {obj}. TorchScript requires source access in \"\n",
            "               \"order to carry out compilation, make sure original .py files are \"\n",
            "               \"available.\")\n",
            "        if error_msg:\n",
            "            msg += '\\n' + error_msg\n",
            "        raise OSError(msg) from e\n",
            "\n",
            "    return sourcelines, file_lineno, filename\n",
            "\n",
            "\n",
            "def normalize_source_lines(sourcelines: List[str]) -> List[str]:\n",
            "    \"\"\"\n",
            "    This helper function accepts a list of source lines. It finds the\n",
            "    indentation level of the function definition (`def`), then it indents\n",
            "    all lines in the function body to a point at or greater than that\n",
            "    level. This allows for comments and continued string literals that\n",
            "    are at a lower indentation than the rest of the code.\n",
            "    Args:\n",
            "        sourcelines: function source code, separated into lines by\n",
            "                        the '\\n' character\n",
            "    Returns:\n",
            "        A list of source lines that have been correctly aligned\n",
            "    \"\"\"\n",
            "\n",
            "    def remove_prefix(text, prefix):\n",
            "        return text[text.startswith(prefix) and len(prefix):]\n",
            "\n",
            "    # Find the line and line number containing the function definition\n",
            "    for i, l in enumerate(sourcelines):\n",
            "        if l.lstrip().startswith(\"def\"):\n",
            "            idx = i\n",
            "            break\n",
            "    fn_def = sourcelines[idx]\n",
            "\n",
            "    # Get a string representing the amount of leading whitespace\n",
            "    whitespace = fn_def.split(\"def\")[0]\n",
            "\n",
            "    # Add this leading whitespace to all lines before and after the `def`\n",
            "    aligned_prefix = [whitespace + remove_prefix(s, whitespace) for s in sourcelines[:idx]]\n",
            "    aligned_suffix = [whitespace + remove_prefix(s, whitespace) for s in sourcelines[idx + 1:]]\n",
            "\n",
            "    # Put it together again\n",
            "    aligned_prefix.append(fn_def)\n",
            "    return aligned_prefix + aligned_suffix\n",
            "\n",
            "\n",
            "# Thin wrapper around SourceRangeFactory to store extra metadata\n",
            "# about the function-to-be-compiled.\n",
            "class SourceContext(SourceRangeFactory):\n",
            "    def __init__(self, source, filename, file_lineno, leading_whitespace_len, uses_true_division=True):\n",
            "        super(SourceContext, self).__init__(source, filename, file_lineno, leading_whitespace_len)\n",
            "        self.uses_true_division = uses_true_division\n",
            "        self.filename = filename\n",
            "\n",
            "\n",
            "@functools.lru_cache(maxsize=None)\n",
            "def make_source_context(*args):\n",
            "    return SourceContext(*args)\n",
            "\n",
            "\n",
            "def fake_range():\n",
            "    return SourceContext('', None, 0, 0).make_raw_range(0, 1)\n",
            "\n",
            "\n",
            "class ParsedDef(NamedTuple):\n",
            "    ast: ast.Module\n",
            "    ctx: SourceContext\n",
            "    source: str\n",
            "    filename: Optional[str]\n",
            "    file_lineno: int\n",
            "\n",
            "def parse_def(fn):\n",
            "    sourcelines, file_lineno, filename = get_source_lines_and_file(fn, ErrorReport.call_stack())\n",
            "    sourcelines = normalize_source_lines(sourcelines)\n",
            "    source = ''.join(sourcelines)\n",
            "    dedent_src = dedent(source)\n",
            "    py_ast = ast.parse(dedent_src)\n",
            "    if len(py_ast.body) != 1 or not isinstance(py_ast.body[0], ast.FunctionDef):\n",
            "        raise RuntimeError(f\"Expected a single top-level function: {filename}:{file_lineno}\")\n",
            "    leading_whitespace_len = len(source.split('\\n', 1)[0]) - len(dedent_src.split('\\n', 1)[0])\n",
            "    ctx = make_source_context(source, filename, file_lineno, leading_whitespace_len, True)\n",
            "    return ParsedDef(py_ast, ctx, source, filename, file_lineno)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6uocTDwkY4zQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FastPitch_Filled HW.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}